{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RamziRBM/lab-text-generation-shakespeare/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVggWzwPYUol"
      },
      "source": [
        "# Lab | Text Generation from Shakespeare's Sonnet\n",
        "\n",
        "This notebook explores the fascinating domain of text generation using a deep learning model trained on Shakespeare's sonnets.\n",
        "\n",
        "The objective is to create a neural network capable of generating text sequences that mimic the style and language of Shakespeare.\n",
        "\n",
        "By utilizing a Recurrent Neural Network (RNN) with Long Short-Term Memory (LSTM) layers, this project aims to demonstrate how a model can learn and replicate the complex patterns of early modern English.\n",
        "\n",
        "The dataset used consists of Shakespeare's sonnets, which are preprocessed and tokenized to serve as input for the model.\n",
        "\n",
        "Throughout this notebook, you will see the steps taken to prepare the data, build and train the model, and evaluate its performance in generating text.\n",
        "\n",
        "This lab provides a hands-on approach to understanding the intricacies of natural language processing (NLP) and the potential of machine learning in creative text generation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rxK83_gYUor"
      },
      "source": [
        "Let's import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BOwsuGQQY9OL",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.utils as ku\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import numpy as np\n",
        "import re\n",
        "from string import punctuation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRLSRZAPYUov"
      },
      "source": [
        "Let's get the data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZfssc42YUow",
        "outputId": "0c2631ab-5738-4601-f851-d67504752aef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:10: SyntaxWarning: invalid escape sequence '\\.'\n",
            "<>:10: SyntaxWarning: invalid escape sequence '\\.'\n",
            "/tmp/ipython-input-1429276763.py:10: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  data = re.sub(r\"[A-Z]+\\.\", \"\", data)\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "url = 'https://raw.githubusercontent.com/martin-gorner/tensorflow-rnn-shakespeare/master/shakespeare/sonnets.txt'\n",
        "resp = requests.get(url)\n",
        "with open('sonnets.txt', 'wb') as f:\n",
        "    f.write(resp.content)\n",
        "\n",
        "data = open('sonnets.txt').read()\n",
        "\"\"\"\n",
        "data = re.sub(r\"FROM fairest\", \"From fairest\", data)\n",
        "data = re.sub(r\"[A-Z]+\\.\", \"\", data)\n",
        "data = re.sub(r\"[A-Z][A-Z\\-]+\\s\", \"\", data)\n",
        "data = re.sub(f\"[{re.escape(punctuation)}]\", \"\", data)\n",
        "data = re.sub(r\"\\n\\s*\\n\", \"\\n\", data)\n",
        "data = re.sub(r\"^\\s*\\n\", \"\", data)\n",
        "data = re.sub(r\"\\s*\\n\", \"\\n\", data)\n",
        "print (data)\n",
        "\"\"\"\n",
        "corpus = data.lower().split(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19M4_iEGYUoz"
      },
      "source": [
        "Step 1: Initialise a tokenizer and fit it on the corpus variable using .fit_on_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nrBdUK6lYUo1"
      },
      "outputs": [],
      "source": [
        "# Your code here :\n",
        "_tokenizer = Tokenizer(num_words=5000)\n",
        "_tokenizer.fit_on_texts(corpus)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OQw9fYxYUo2"
      },
      "source": [
        "Step 2: Calculate the Vocabulary Size\n",
        "\n",
        "Let's figure out how many unique words are in your corpus. This will be the size of your vocabulary.\n",
        "\n",
        "Calculate the length of tokenizer.word_index, add 1 to it and store it in a variable called total_words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxesfP4OYUo3",
        "outputId": "c22e0d57-1ea2-4f63-e3cb-b2c26e7ce8ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3375"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Your code here :\n",
        "total_words = len(_tokenizer.word_index) + 1\n",
        "total_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTSsLHaUYUo4"
      },
      "source": [
        "Create an empty list called input_sequences.\n",
        "\n",
        "For each sentence in your corpus, convert the text into a sequence of integers using the tokenizer.\n",
        "Then, generate n-gram sequences from these tokens.\n",
        "\n",
        "Store the result in the list input_sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AmEBdLICYUo4",
        "outputId": "f5e9549b-e1fd-4ef0-bb06-79e50accacb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Your code here :\n",
        "Labels = []\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "    token_list = _tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXK_z67DYUo5"
      },
      "source": [
        "Calculate the length of the longest sequence in input_sequences. Assign the result to a variable called max_sequence_len.\n",
        "\n",
        "Now pad the sequences using pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre').\n",
        "Convert it to a numpy array and assign the result back to our variable called input_sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DfSAosXYUo5",
        "outputId": "140f3c8d-3d13-4208-a4ae-cebd7f665184"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,    0,    3,    2],\n",
              "       [   0,    0,    0, ...,    3,    2,  313],\n",
              "       [   0,    0,    0, ...,    2,  313, 1375],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,  493,  493, 3374],\n",
              "       [   0,    0,    0, ...,  493, 3374,   14],\n",
              "       [   0,    0,    0, ..., 3374,   14,   15]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Your code here :\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "print(max_sequence_len)\n",
        "input_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpLiZ-9bYUo6"
      },
      "source": [
        "Prepare Predictors and Labels\n",
        "\n",
        "Split the sequences into two parts:\n",
        "\n",
        "- Predictors: All elements from input_sequences except the last one.\n",
        "- Labels: The last element of each sequence in input_sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PRnDnCW-Z7qv",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Your code here :\n",
        "Predictors, Labels = input_sequences[:,:-1],input_sequences[:,-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnXioo_SYUo6"
      },
      "source": [
        "One-Hot Encode the Labels :\n",
        "\n",
        "Convert the labels (which are integers) into one-hot encoded vectors.\n",
        "\n",
        "Ensure the length of these vectors matches the total number of unique words in your vocabulary.\n",
        "\n",
        "Use ku.to_categorical() on labels with num_classes = total_words\n",
        "\n",
        "Assign the result back to our variable labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lj7dwBLYUo6",
        "outputId": "c3911349-dcba-46f2-9df7-dd3b01921feb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15484, 3375)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Your code here :\n",
        "Labels = ku.to_categorical(Labels, num_classes=total_words)\n",
        "Labels.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EqGoIraYUo7"
      },
      "source": [
        "# Initialize the Model\n",
        "\n",
        "Start by creating a Sequential model.\n",
        "\n",
        "Add Layers to the Model:\n",
        "\n",
        "Embedding Layer: The first layer is an embedding layer. It converts word indices into dense vectors of fixed size (100 in this case). Set the input length to the maximum sequence length minus one, which corresponds to the number of previous words the model will consider when predicting the next word.\n",
        "\n",
        "Bidirectional LSTM Layer: Add a Bidirectional LSTM layer with 150 units. This layer allows the model to learn context from both directions (past and future) in the sequence. return_sequences=True\n",
        "\n",
        "Dropout Layer: Add a dropout layer with a rate of 0.2 to prevent overfitting by randomly setting 20% of the input units to 0 during training.\n",
        "\n",
        "LSTM Layer: Add a second LSTM layer with 100 units. This layer processes the sequence and passes its output to the next layer.\n",
        "\n",
        "Dense Layer (Intermediate): Add a dense layer with half the total number of words as units, using ReLU activation. A regularization term (L2) is added to prevent overfitting.\n",
        "\n",
        "Dense Layer (Output): The final dense layer has as many units as there are words in the vocabulary, with a softmax activation function to output a probability distribution over all words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpA2OPGpYUo7",
        "outputId": "653732da-9531-45b4-dd71-a30506870d92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    # Your code here :\n",
        "    layers.Embedding(input_dim=total_words, output_dim=100, input_length=max_sequence_len-1),\n",
        "    layers.Bidirectional(LSTM(150, return_sequences=True)),\n",
        "    layers.Dropout(0.2),\n",
        "    #layers.Bidirectional(LSTM(100)),\n",
        "    layers.LSTM(100),\n",
        "    layers.Dense(total_words//2, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    layers.Dense(total_words, activation=\"softmax\"),\n",
        "\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0uIK23RYUo8"
      },
      "source": [
        "# Compile the Model:\n",
        "\n",
        "Compile the model using categorical crossentropy as the loss function, the Adam optimizer for efficient training, and accuracy as the metric to evaluate during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "97z2DvVCYUo8"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.build(input_shape=(None, max_sequence_len-1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GZCscdfYUo8"
      },
      "source": [
        "# Print Model Summary:\n",
        "\n",
        "Use model.summary() to print a summary of the model, which shows the layers, their output shapes, and the number of parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "dFIYF6TgYUo9",
        "outputId": "b48f56f6-cd70-4341-ae96-911c094cef86"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │       \u001b[38;5;34m337,500\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │       \u001b[38;5;34m301,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m160,400\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1687\u001b[0m)           │       \u001b[38;5;34m170,387\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3375\u001b[0m)           │     \u001b[38;5;34m5,697,000\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">337,500</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">301,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">160,400</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1687</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">170,387</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3375</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,697,000</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,666,487\u001b[0m (25.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,666,487</span> (25.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,666,487\u001b[0m (25.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,666,487</span> (25.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Evwepg9ZYUo9"
      },
      "source": [
        "# Now train the model for 50 epochs and assign it to a variable called history.\n",
        "\n",
        "Training the model with 50 epochs should get you around 40% accuracy.\n",
        "\n",
        "You can train the model for as many epochs as you like depending on the time and computing constraints you are facing. Ideally train it for a larger amount of epochs than 50.\n",
        "\n",
        "That way you will get better text generation at the end.\n",
        "\n",
        "However, dont waste your time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "AIg2f1HBxqof",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "from sklearn.model_selection import train_test_split\n",
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(Predictors, Labels, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Predictors.shape)\n",
        "\n",
        "history = model.fit(Xtrain, Ytrain, epochs=150, verbose=1, validation_split=0.1)"
      ],
      "metadata": {
        "id": "xcDUbbXI9hcX",
        "outputId": "72a67575-38d2-426b-ea84-d0e0eae2437d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15484, 10)\n",
            "Epoch 1/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.0189 - loss: 7.4695 - val_accuracy: 0.0202 - val_loss: 6.7101\n",
            "Epoch 2/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.0260 - loss: 6.4501 - val_accuracy: 0.0202 - val_loss: 6.8163\n",
            "Epoch 3/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.0228 - loss: 6.3532 - val_accuracy: 0.0234 - val_loss: 6.9322\n",
            "Epoch 4/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.0235 - loss: 6.2765 - val_accuracy: 0.0194 - val_loss: 7.0269\n",
            "Epoch 5/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.0295 - loss: 6.1799 - val_accuracy: 0.0202 - val_loss: 7.1426\n",
            "Epoch 6/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.0344 - loss: 6.0693 - val_accuracy: 0.0258 - val_loss: 7.1650\n",
            "Epoch 7/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.0379 - loss: 5.9947 - val_accuracy: 0.0299 - val_loss: 7.3962\n",
            "Epoch 8/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.0422 - loss: 5.9268 - val_accuracy: 0.0315 - val_loss: 7.3233\n",
            "Epoch 9/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.0420 - loss: 5.8607 - val_accuracy: 0.0323 - val_loss: 7.5278\n",
            "Epoch 10/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.0505 - loss: 5.7895 - val_accuracy: 0.0363 - val_loss: 7.6371\n",
            "Epoch 11/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.0498 - loss: 5.7386 - val_accuracy: 0.0347 - val_loss: 7.7598\n",
            "Epoch 12/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.0553 - loss: 5.6475 - val_accuracy: 0.0387 - val_loss: 7.8621\n",
            "Epoch 13/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.0573 - loss: 5.5782 - val_accuracy: 0.0404 - val_loss: 8.0103\n",
            "Epoch 14/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.0651 - loss: 5.4841 - val_accuracy: 0.0420 - val_loss: 8.0162\n",
            "Epoch 15/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.0681 - loss: 5.3698 - val_accuracy: 0.0420 - val_loss: 8.2537\n",
            "Epoch 16/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.0720 - loss: 5.2975 - val_accuracy: 0.0395 - val_loss: 8.4145\n",
            "Epoch 17/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.0821 - loss: 5.2116 - val_accuracy: 0.0460 - val_loss: 8.4853\n",
            "Epoch 18/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.0808 - loss: 5.1177 - val_accuracy: 0.0428 - val_loss: 8.5137\n",
            "Epoch 19/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.0880 - loss: 5.0215 - val_accuracy: 0.0420 - val_loss: 8.7804\n",
            "Epoch 20/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.0968 - loss: 4.9213 - val_accuracy: 0.0452 - val_loss: 8.8737\n",
            "Epoch 21/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.1016 - loss: 4.8424 - val_accuracy: 0.0412 - val_loss: 9.2194\n",
            "Epoch 22/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.1105 - loss: 4.7313 - val_accuracy: 0.0412 - val_loss: 9.5646\n",
            "Epoch 23/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.1179 - loss: 4.6589 - val_accuracy: 0.0379 - val_loss: 9.8631\n",
            "Epoch 24/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.1250 - loss: 4.5605 - val_accuracy: 0.0404 - val_loss: 9.9731\n",
            "Epoch 25/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.1339 - loss: 4.4594 - val_accuracy: 0.0412 - val_loss: 10.3006\n",
            "Epoch 26/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.1455 - loss: 4.3588 - val_accuracy: 0.0347 - val_loss: 10.6916\n",
            "Epoch 27/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.1547 - loss: 4.2658 - val_accuracy: 0.0331 - val_loss: 11.1052\n",
            "Epoch 28/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.1675 - loss: 4.1620 - val_accuracy: 0.0347 - val_loss: 11.4055\n",
            "Epoch 29/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.1876 - loss: 4.0326 - val_accuracy: 0.0323 - val_loss: 11.6582\n",
            "Epoch 30/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.2059 - loss: 3.9186 - val_accuracy: 0.0315 - val_loss: 12.0348\n",
            "Epoch 31/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.2178 - loss: 3.8477 - val_accuracy: 0.0323 - val_loss: 12.5019\n",
            "Epoch 32/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.2430 - loss: 3.7324 - val_accuracy: 0.0363 - val_loss: 12.8241\n",
            "Epoch 33/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.2555 - loss: 3.6499 - val_accuracy: 0.0299 - val_loss: 13.1509\n",
            "Epoch 34/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.2862 - loss: 3.5585 - val_accuracy: 0.0291 - val_loss: 13.4675\n",
            "Epoch 35/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.2981 - loss: 3.4625 - val_accuracy: 0.0291 - val_loss: 13.8602\n",
            "Epoch 36/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.3200 - loss: 3.3898 - val_accuracy: 0.0307 - val_loss: 14.2607\n",
            "Epoch 37/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.3349 - loss: 3.3138 - val_accuracy: 0.0266 - val_loss: 14.4426\n",
            "Epoch 38/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.3546 - loss: 3.2117 - val_accuracy: 0.0307 - val_loss: 14.8778\n",
            "Epoch 39/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.3752 - loss: 3.1448 - val_accuracy: 0.0250 - val_loss: 15.0866\n",
            "Epoch 40/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.3980 - loss: 3.0479 - val_accuracy: 0.0258 - val_loss: 15.4814\n",
            "Epoch 41/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.4101 - loss: 2.9875 - val_accuracy: 0.0299 - val_loss: 15.7641\n",
            "Epoch 42/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.4339 - loss: 2.8980 - val_accuracy: 0.0307 - val_loss: 16.1476\n",
            "Epoch 43/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.4461 - loss: 2.8652 - val_accuracy: 0.0266 - val_loss: 16.3951\n",
            "Epoch 44/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.4600 - loss: 2.7740 - val_accuracy: 0.0266 - val_loss: 16.5341\n",
            "Epoch 45/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.4762 - loss: 2.7237 - val_accuracy: 0.0299 - val_loss: 16.8291\n",
            "Epoch 46/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.4892 - loss: 2.6750 - val_accuracy: 0.0274 - val_loss: 17.1442\n",
            "Epoch 47/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.5103 - loss: 2.5642 - val_accuracy: 0.0299 - val_loss: 17.1957\n",
            "Epoch 48/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.5312 - loss: 2.4956 - val_accuracy: 0.0274 - val_loss: 17.3772\n",
            "Epoch 49/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.5346 - loss: 2.4703 - val_accuracy: 0.0258 - val_loss: 17.6025\n",
            "Epoch 50/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.5485 - loss: 2.3946 - val_accuracy: 0.0266 - val_loss: 17.7838\n",
            "Epoch 51/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.5640 - loss: 2.3466 - val_accuracy: 0.0274 - val_loss: 18.0601\n",
            "Epoch 52/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.5773 - loss: 2.3026 - val_accuracy: 0.0282 - val_loss: 18.2766\n",
            "Epoch 53/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.5852 - loss: 2.2577 - val_accuracy: 0.0250 - val_loss: 18.5272\n",
            "Epoch 54/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.6025 - loss: 2.2045 - val_accuracy: 0.0299 - val_loss: 18.4456\n",
            "Epoch 55/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.6113 - loss: 2.1466 - val_accuracy: 0.0274 - val_loss: 18.7432\n",
            "Epoch 56/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.6272 - loss: 2.0752 - val_accuracy: 0.0258 - val_loss: 18.9144\n",
            "Epoch 57/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.6360 - loss: 2.0563 - val_accuracy: 0.0331 - val_loss: 19.0117\n",
            "Epoch 58/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.6405 - loss: 2.0245 - val_accuracy: 0.0282 - val_loss: 19.2281\n",
            "Epoch 59/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.6606 - loss: 1.9384 - val_accuracy: 0.0315 - val_loss: 19.1402\n",
            "Epoch 60/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.6575 - loss: 1.9470 - val_accuracy: 0.0291 - val_loss: 19.2824\n",
            "Epoch 61/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.6734 - loss: 1.9085 - val_accuracy: 0.0331 - val_loss: 19.2806\n",
            "Epoch 62/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.6795 - loss: 1.8509 - val_accuracy: 0.0266 - val_loss: 19.6838\n",
            "Epoch 63/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.6920 - loss: 1.8223 - val_accuracy: 0.0234 - val_loss: 19.6889\n",
            "Epoch 64/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.6875 - loss: 1.8146 - val_accuracy: 0.0242 - val_loss: 19.7146\n",
            "Epoch 65/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.7093 - loss: 1.7305 - val_accuracy: 0.0291 - val_loss: 19.8091\n",
            "Epoch 66/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.7098 - loss: 1.7213 - val_accuracy: 0.0307 - val_loss: 19.7405\n",
            "Epoch 67/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.7085 - loss: 1.6978 - val_accuracy: 0.0258 - val_loss: 20.1151\n",
            "Epoch 68/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7063 - loss: 1.6911 - val_accuracy: 0.0242 - val_loss: 19.9938\n",
            "Epoch 69/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.7383 - loss: 1.6033 - val_accuracy: 0.0274 - val_loss: 19.9499\n",
            "Epoch 70/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.7428 - loss: 1.5740 - val_accuracy: 0.0258 - val_loss: 20.0558\n",
            "Epoch 71/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.7449 - loss: 1.5671 - val_accuracy: 0.0282 - val_loss: 20.0288\n",
            "Epoch 72/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.7416 - loss: 1.5437 - val_accuracy: 0.0291 - val_loss: 20.0028\n",
            "Epoch 73/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.7536 - loss: 1.5267 - val_accuracy: 0.0299 - val_loss: 20.1669\n",
            "Epoch 74/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.7584 - loss: 1.4774 - val_accuracy: 0.0258 - val_loss: 20.4216\n",
            "Epoch 75/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.7624 - loss: 1.4733 - val_accuracy: 0.0266 - val_loss: 20.3562\n",
            "Epoch 76/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.7695 - loss: 1.4341 - val_accuracy: 0.0250 - val_loss: 20.4027\n",
            "Epoch 77/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.7655 - loss: 1.4329 - val_accuracy: 0.0258 - val_loss: 20.4513\n",
            "Epoch 78/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.7770 - loss: 1.3868 - val_accuracy: 0.0258 - val_loss: 20.3595\n",
            "Epoch 79/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.7771 - loss: 1.3850 - val_accuracy: 0.0307 - val_loss: 20.4331\n",
            "Epoch 80/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.7841 - loss: 1.3526 - val_accuracy: 0.0291 - val_loss: 20.4901\n",
            "Epoch 81/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7874 - loss: 1.3296 - val_accuracy: 0.0226 - val_loss: 20.5752\n",
            "Epoch 82/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.7900 - loss: 1.3143 - val_accuracy: 0.0266 - val_loss: 20.4967\n",
            "Epoch 83/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.7969 - loss: 1.2983 - val_accuracy: 0.0226 - val_loss: 20.2544\n",
            "Epoch 84/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7897 - loss: 1.2927 - val_accuracy: 0.0266 - val_loss: 20.5887\n",
            "Epoch 85/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.7933 - loss: 1.2796 - val_accuracy: 0.0291 - val_loss: 20.6614\n",
            "Epoch 86/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7989 - loss: 1.2531 - val_accuracy: 0.0274 - val_loss: 20.6619\n",
            "Epoch 87/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8007 - loss: 1.2409 - val_accuracy: 0.0323 - val_loss: 20.6392\n",
            "Epoch 88/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7990 - loss: 1.2395 - val_accuracy: 0.0307 - val_loss: 20.5164\n",
            "Epoch 89/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8165 - loss: 1.1790 - val_accuracy: 0.0299 - val_loss: 20.5873\n",
            "Epoch 90/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8121 - loss: 1.1954 - val_accuracy: 0.0274 - val_loss: 20.4155\n",
            "Epoch 91/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.8141 - loss: 1.1641 - val_accuracy: 0.0242 - val_loss: 20.6420\n",
            "Epoch 92/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8179 - loss: 1.1522 - val_accuracy: 0.0291 - val_loss: 20.6022\n",
            "Epoch 93/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8242 - loss: 1.1188 - val_accuracy: 0.0291 - val_loss: 20.4168\n",
            "Epoch 94/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.8125 - loss: 1.1586 - val_accuracy: 0.0234 - val_loss: 20.6598\n",
            "Epoch 95/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8256 - loss: 1.0970 - val_accuracy: 0.0226 - val_loss: 20.4555\n",
            "Epoch 96/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.8241 - loss: 1.1201 - val_accuracy: 0.0282 - val_loss: 20.5990\n",
            "Epoch 97/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8171 - loss: 1.1300 - val_accuracy: 0.0250 - val_loss: 20.5300\n",
            "Epoch 98/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8277 - loss: 1.0766 - val_accuracy: 0.0274 - val_loss: 20.4569\n",
            "Epoch 99/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.8260 - loss: 1.0880 - val_accuracy: 0.0299 - val_loss: 20.4036\n",
            "Epoch 100/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8295 - loss: 1.0777 - val_accuracy: 0.0250 - val_loss: 20.5487\n",
            "Epoch 101/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8286 - loss: 1.0661 - val_accuracy: 0.0258 - val_loss: 20.4842\n",
            "Epoch 102/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8355 - loss: 1.0416 - val_accuracy: 0.0266 - val_loss: 20.4517\n",
            "Epoch 103/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8322 - loss: 1.0422 - val_accuracy: 0.0274 - val_loss: 20.4644\n",
            "Epoch 104/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8372 - loss: 1.0085 - val_accuracy: 0.0282 - val_loss: 20.5148\n",
            "Epoch 105/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8356 - loss: 1.0210 - val_accuracy: 0.0210 - val_loss: 20.5433\n",
            "Epoch 106/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8287 - loss: 1.0230 - val_accuracy: 0.0258 - val_loss: 20.2635\n",
            "Epoch 107/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8367 - loss: 1.0035 - val_accuracy: 0.0258 - val_loss: 20.6159\n",
            "Epoch 108/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8482 - loss: 0.9792 - val_accuracy: 0.0242 - val_loss: 20.4974\n",
            "Epoch 109/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8449 - loss: 0.9743 - val_accuracy: 0.0307 - val_loss: 20.5293\n",
            "Epoch 110/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8456 - loss: 0.9494 - val_accuracy: 0.0282 - val_loss: 20.2290\n",
            "Epoch 111/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8423 - loss: 0.9714 - val_accuracy: 0.0266 - val_loss: 20.3887\n",
            "Epoch 112/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8434 - loss: 0.9526 - val_accuracy: 0.0274 - val_loss: 20.2470\n",
            "Epoch 113/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8383 - loss: 0.9590 - val_accuracy: 0.0274 - val_loss: 20.1981\n",
            "Epoch 114/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8448 - loss: 0.9459 - val_accuracy: 0.0282 - val_loss: 20.5045\n",
            "Epoch 115/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.8398 - loss: 0.9507 - val_accuracy: 0.0274 - val_loss: 20.3986\n",
            "Epoch 116/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8474 - loss: 0.9207 - val_accuracy: 0.0274 - val_loss: 20.3670\n",
            "Epoch 117/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8420 - loss: 0.9390 - val_accuracy: 0.0242 - val_loss: 20.2562\n",
            "Epoch 118/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8518 - loss: 0.8993 - val_accuracy: 0.0291 - val_loss: 20.2296\n",
            "Epoch 119/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8492 - loss: 0.9190 - val_accuracy: 0.0307 - val_loss: 20.2543\n",
            "Epoch 120/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8463 - loss: 0.9109 - val_accuracy: 0.0250 - val_loss: 20.2094\n",
            "Epoch 121/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8473 - loss: 0.9077 - val_accuracy: 0.0210 - val_loss: 20.2717\n",
            "Epoch 122/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.8553 - loss: 0.8781 - val_accuracy: 0.0234 - val_loss: 20.2130\n",
            "Epoch 123/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8477 - loss: 0.8885 - val_accuracy: 0.0242 - val_loss: 20.1859\n",
            "Epoch 124/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.8471 - loss: 0.8980 - val_accuracy: 0.0266 - val_loss: 20.1513\n",
            "Epoch 125/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8541 - loss: 0.8645 - val_accuracy: 0.0218 - val_loss: 20.1022\n",
            "Epoch 126/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8488 - loss: 0.8844 - val_accuracy: 0.0266 - val_loss: 20.0946\n",
            "Epoch 127/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8553 - loss: 0.8407 - val_accuracy: 0.0291 - val_loss: 20.0533\n",
            "Epoch 128/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8484 - loss: 0.8851 - val_accuracy: 0.0242 - val_loss: 20.3821\n",
            "Epoch 129/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8479 - loss: 0.8636 - val_accuracy: 0.0258 - val_loss: 20.4805\n",
            "Epoch 130/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8474 - loss: 0.8709 - val_accuracy: 0.0250 - val_loss: 20.2346\n",
            "Epoch 131/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8470 - loss: 0.8756 - val_accuracy: 0.0242 - val_loss: 20.0721\n",
            "Epoch 132/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8504 - loss: 0.8430 - val_accuracy: 0.0226 - val_loss: 20.0694\n",
            "Epoch 133/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8474 - loss: 0.8522 - val_accuracy: 0.0234 - val_loss: 19.8817\n",
            "Epoch 134/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8582 - loss: 0.8219 - val_accuracy: 0.0266 - val_loss: 20.0744\n",
            "Epoch 135/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8514 - loss: 0.8362 - val_accuracy: 0.0194 - val_loss: 20.0482\n",
            "Epoch 136/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8527 - loss: 0.8194 - val_accuracy: 0.0234 - val_loss: 20.1427\n",
            "Epoch 137/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8569 - loss: 0.8345 - val_accuracy: 0.0258 - val_loss: 20.1786\n",
            "Epoch 138/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8559 - loss: 0.8138 - val_accuracy: 0.0274 - val_loss: 19.8236\n",
            "Epoch 139/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8500 - loss: 0.8251 - val_accuracy: 0.0234 - val_loss: 20.1511\n",
            "Epoch 140/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8533 - loss: 0.8165 - val_accuracy: 0.0266 - val_loss: 20.0423\n",
            "Epoch 141/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8548 - loss: 0.8187 - val_accuracy: 0.0274 - val_loss: 20.1400\n",
            "Epoch 142/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8516 - loss: 0.8181 - val_accuracy: 0.0266 - val_loss: 19.9548\n",
            "Epoch 143/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8559 - loss: 0.8083 - val_accuracy: 0.0282 - val_loss: 20.0226\n",
            "Epoch 144/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8602 - loss: 0.7958 - val_accuracy: 0.0258 - val_loss: 19.9362\n",
            "Epoch 145/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8555 - loss: 0.7971 - val_accuracy: 0.0299 - val_loss: 20.0832\n",
            "Epoch 146/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8550 - loss: 0.7824 - val_accuracy: 0.0202 - val_loss: 19.9478\n",
            "Epoch 147/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8562 - loss: 0.8021 - val_accuracy: 0.0242 - val_loss: 20.0063\n",
            "Epoch 148/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8579 - loss: 0.7720 - val_accuracy: 0.0250 - val_loss: 19.9667\n",
            "Epoch 149/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8578 - loss: 0.7796 - val_accuracy: 0.0266 - val_loss: 19.7808\n",
            "Epoch 150/150\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8536 - loss: 0.7852 - val_accuracy: 0.0266 - val_loss: 20.0123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHM_eMTuYUo9"
      },
      "source": [
        "# Use plt from matplotlib to plot the training accuracy over epochs and the loss over epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7Puu9duYUo9"
      },
      "source": [
        "First you will have to get the accuracy and loss data over epochs, you can do this by using methods on your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1fXTEO3GJ282",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "e0e302df-7594-464e-d8d9-b69f8a13a1e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====  2nd model  =====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_accuracy(history, descr):\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  plt.figure(figsize=(5, 5))\n",
        "  plt.plot(acc)\n",
        "  plt.plot(val_acc)\n",
        "  #plt.plot(loss)\n",
        " # plt.plot(val_loss)\n",
        "  plt.title(\"model accuracy \"+descr)\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
        "  plt.show()\n",
        "\n",
        "#plot_accuracy(history, \"first model\")\n",
        "print(\"====  2nd model  =====\")\n",
        "plot_accuracy(history, \"second model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFgwFL5dYUo-"
      },
      "source": [
        "# Generate text with the model based on a seed text\n",
        "\n",
        "Now you will create two variables :\n",
        "\n",
        "- seed_text = 'Write the text you want the model to use as a starting point to generate the next words'\n",
        "- next_words = number_of_words_you_want_the_model_to_generate\n",
        "\n",
        "Please change number_of_words_you_want_the_model_to_generate by an actual integer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oUrv46RfYUo-"
      },
      "outputs": [],
      "source": [
        "# Your code here :# Your code here :\n",
        "seed_txt = 'To be, or not to be, that'\n",
        "next_words = 100 # You can change this number to generate more or less words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oEiFp6OYUo_"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "Now create a loop that runs based on the next_words variable and generates new text based on your seed_text input string. Print the full text with the generated text at the end.\n",
        "\n",
        "This time you dont get detailed instructions.\n",
        "\n",
        "Have fun!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6Vc6PHgxa6Hm",
        "tags": [],
        "outputId": "b3906dfa-c263-457a-87fb-e37ac6c24c22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To be, or not to be, that it stay of good sight cross rare men look you made must three chest lie affords depend cross cross cross stand back to me true true friend so true well knows eyes men's blot friend true well friend do me be shown love mine eyes see thee more true being back again defaced yet her end must have men's due of thy sight cross grow groan did lie to his stars living treasure i true deeds friend in me be thee shown but me alone made to true glory so 'no ' friend to me was love love love so\n"
          ]
        }
      ],
      "source": [
        "def generate_sonnets(seed_text):\n",
        "  for _ in range(next_words):\n",
        "    # Convert seed text to sequence\n",
        "    token_list = _tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\n",
        "    # Predict next word\n",
        "    predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)\n",
        "\n",
        "    # ✅ Extract the last predicted word\n",
        "    predicted_index = predicted[0]\n",
        "\n",
        "    # Find the word corresponding to the predicted index\n",
        "    output_word = \"\"\n",
        "    for word, index in _tokenizer.word_index.items():\n",
        "        if index == predicted_index:\n",
        "            output_word = word\n",
        "            break\n",
        "\n",
        "    # Append it to the sentence\n",
        "    seed_text += \" \" + output_word\n",
        "  return seed_text\n",
        "\n",
        "print(generate_sonnets(seed_txt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo-DiXxYYUpA"
      },
      "source": [
        "Experiment with at least 3 different seed_text strings and see what happens!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_sonnets(\"what I would improvise\"))"
      ],
      "metadata": {
        "id": "Q8lo3jED_Cqw",
        "outputId": "f3836609-b6a7-4556-b509-155e1bc2ffd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what I would improvise see the seemly raiment of thy days must rehearse rehearse find to flow delight sight wit true true bright back more more more more re did new minutes store doth stand in thy woe ' friend words ' heir ' lips grief decay was taste ' bad still decay good skill hide them well so brought fitted stand in thy hand are rehearse deem'd grow treasure the sum of his moan did hate did other part are day things things had dead date 'will' pleasure owe despair her rage are wretched more are bright sight than thee hate alone brain\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_sonnets(\"Romeo was a \"))"
      ],
      "metadata": {
        "id": "1gTw6Nr__Cao",
        "outputId": "29a99908-3d74-40a1-98fd-dd9057836bb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Romeo was a  babe hath but love's virtue more eyed ' friend to thee true true praise thee call taste was me dead fire bring do thy breast still put my life to his legacy sheds flattery in thee show thee friend me swear fast made joy mine own praise still seem thy hair still decay worse still state was her pace keep is me poor mask'd thou so my heart when thee other kiss thee shown despise shown wrong ' friend in his son back eye so true well form alone more ground growing life was decays made hearts is day are\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "86a9jSFLYUpB",
        "outputId": "91f4f94d-ddb7-4a6c-839e-38cc034f599d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Julliette was a  babe hath but love's virtue more eyed ' friend to thee true true praise thee call taste was me dead fire bring do thy breast still put my life to his legacy sheds flattery in thee show thee friend me swear fast made joy mine own praise still seem thy hair still decay worse still state was her pace keep is me poor mask'd thou so my heart when thee other kiss thee shown despise shown wrong ' friend in his son back eye so true well form alone more ground growing life was decays made hearts is day are\n"
          ]
        }
      ],
      "source": [
        "# Your code here :\n",
        "print(generate_sonnets(\"Julliette was a \"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_sonnets(\"Romeo used to be \"))"
      ],
      "metadata": {
        "id": "ptWZJChhBK7z",
        "outputId": "dcf4231a-66de-44e2-d685-f84b590f9772",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Romeo used to be  error and with him our appetites than thee alone than untrue love conscience is bears the same friend yet mine eye so cover thou blind life still true true friend so i so see thou blind mind being pride from thee you live untold live none true glory be level in thee true true true true tongue must sweetly stay of all hearts dead treasure a cheer must be taste ' nor to rehearse rare bear thee dead friend that when me am the worst to your head dead treasure to show thee wealth ever me dead treasure thy show\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NLP_Week4_Exercise_Shakespeare_Answer.ipynb",
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}